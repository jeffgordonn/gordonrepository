{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c273c17f",
   "metadata": {},
   "source": [
    "# Jeff's Notes on Data Science Methodology for Coursera.\n",
    "#### These are public for my own practice of Jupyter Notebooks. If you are taking the course, I recommend writing your own notes as you will not understand the content by watching the videos straight through. Previous section notes are handwritten in my notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695b5e0",
   "metadata": {},
   "source": [
    "## Ungraded Plugin: CRISP-DM (Cross Industry Process for Data Mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd71bf6",
   "metadata": {},
   "source": [
    "CRISP-DM is a methodology process aimed at increasing the use of data mining over a wide variety of business applications and industries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154230c",
   "metadata": {},
   "source": [
    "- Intent: take case specific scenarios and general behaviors to make them domain neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141300dd",
   "metadata": {},
   "source": [
    "#### Six Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df634d",
   "metadata": {},
   "source": [
    "1. __Business Understanding__- MOST IMPORTANT STAGE. This is where the intention of the project is outlined. Requires communication and clarity. Difficulty is that stakeholders have different objectives, biases, and modalities of relating information. Without clear, concise,, and complete perspective of what the project goals are resources will be needlessly expended.\n",
    "2. __Data Understanding__- Relies on Business Understanding. Data is collected at this stage, and the business understanding will determine what data is collected, where from, and by what methods. This stage combines the stages of Data Requirements, Data Collection, and Data Understanding from the Foundational Methodoloy online.\n",
    "3. __Data Preparation__- Once data is collected, it must be transformed into a usable asset unless it is determined more data is needed. Once a dataset is choosen, it must be checked for questionable, missing, or ambigious cases.\n",
    "4. __Modeling__- Once prepared for use, the data must be experessed through whatever appropriate models, ggive meaningful insights, and hopefully new knowledge. This is the purpose of data mining: to create knowledge information that has meaning and utility. Use of models reveals patterns and structures within the data that provide insight into the features of interest. Models are selected on a portion of the data and adjustments are made if necessary. Best to think of it both as an art and science.\n",
    "5. __Evaluation__- Selected model must be tested. Usually done by having a pre-selected test, set to run the trained model on. Allows you to see the effectiveness of the model on a new set. Results determine efficacy of the model and foreshadows its role in the next and final stage.\n",
    "6. __Deployment__- Model is used on new data outside the scope of the dataset and by new stakeholders. New interaction at this phase might reveal the new variables and needs for the dataset and model. These new challenges could initiate revision of either business needs and actions, or the model and data, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b42a0",
   "metadata": {},
   "source": [
    "CRISP_DM is a highly flexible and cyclical model.\n",
    "- Flexibility is required at each step along with communication to keep the project on track. __REMEMBER__, at any point of the six stages, it may be necessary to _revisit an earlier stage and make changes_.\n",
    "- The key point of this process is that it's cyclical; therefore, even at the finish you are having another business understanding encounter to discuss the viability after deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17226a60",
   "metadata": {},
   "source": [
    "## Video 2 - Business Understanding\n",
    "Importance of Questions - data science methodology begins with spending the time to seek clarification, to attain business understanding\n",
    "- _What is the problem that you are trying to solve_? Rollins suggests that having a clearly defined question is vital because it ultimately directs the analytic approach that will be needed to address the question.\n",
    "    - All too often, much effort is put into answering what people THINK is the question and while the methods used to solve that question maybe sound, they do not solve the __actual problem__\n",
    "Establishing a clearly defined question starts with understanding the GOAL of the person who is asking the question.\n",
    "ex. A business owner asks \"How can we reduce the costs of performing an activity?\"\n",
    "- We need to understand, are we trying to increase the efficiency of the activity or is it to increase the business' profitability?\n",
    "Once the goal is clarified, the next piece of the puzzle is to figure out the objecitves that are in support of the goal.\n",
    "- By breaking down the objectives, structured discussions can take place where priorities can be identified in a way that can lead to organizing and planning on how to tackle the problem\n",
    "Different stakeholders will be needed to be engaged in the discussion to help determine the requirments and clarify the questions.\n",
    "\n",
    "__Case Study__ - QUESTION: What is the best way to allocate the limited healthcare budget to maximize its use in providing quality care?\n",
    "- Became a hot topic for an American Healthcare Insurance Provider\n",
    "- As public funding for readmissions was decreasing, this insurance company was at risk of having to make up for the cost difference, which could potentially increase rates for its customers.\n",
    "- Upon review, the team identified \"patient readmissions\" as an effective area for review\n",
    "    - With the goals and objectives in mind, it was found that approx 30% of individuals who finish rehab treatment would be readmitted to a rehab center within one year and that 50% would be readmitted in 5 years\n",
    "    - After reviewing some records, it was discovered that the patients with congestive heart failure were at the top of the readmission list. It was determined that decision-tree model could be applied to review this scenario, to determine why this was occuring\n",
    "- The key business sponsers involvement throughout the project was critical, in that the sponser:\n",
    "    1. Set overall direction\n",
    "    2. Remained engaged and provide guidance\n",
    "    3. Ensured necessary support, where needed\n",
    "- Identified 4 key requirements for the model:\n",
    "    1. Predict CHF readmission outcome (Y or N) for each patient\n",
    "    2. Predict the readmission risk for each patient\n",
    "    3. Understand explicitly what combination of events led to the predicted outcome for each patient\n",
    "    4. Easy to understand and apply to new patients to predict their readmission risk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c0a2d9",
   "metadata": {},
   "source": [
    "## Video 3 - Analytic Approach\n",
    "Selecting the correct analytic approach depend on the question being asked.\n",
    "- Approach involves seeking clarification from person asking the quesiton so enable yourself to pick the most appropriate path\n",
    "Once the problem to be addressed is defined, the approriate analytic approach for the problem is slected in the context of the business requirement.\n",
    "Once a strong understanding of the question is established, the analytic approach can be selected.\n",
    "- This involves identifying what types of patterns that will address the business question most effectively\n",
    "    - If the question is to determine probabilities of an action: Use a Predictive Model\n",
    "    - If the question is to show relationships: Use a descriptive model\n",
    "    - If the question requires a yes/no answer: Use a classification model\n",
    "- Statisitical Analysis applies to problems that requires counts.\n",
    "\n",
    "Machine Learning can be used to identify relationships and trends in data that might otherwise not be accessible or identified.\n",
    "- When the question pertains to learning about human behavior, it may be approriate to use clustering associating approaches.\n",
    "\n",
    "__Case Study__ Decision-Tree classication model was used to identify the combination of conditions leading to each patient's outcome.\n",
    "- Examining the variables in each of the nodes along each path to a leaf, led to a respective threshold\n",
    "- This means the decision-tree classifier provides both the predicted outcome, as well as the likelihood of that outcome, based on the proportion at the dominant outcome, yes or no, in each group\n",
    "    - From this information, the analysts can obtain the readmission risk, or the likelihood of a yes for each patient.\n",
    "    - If the dominant outcome is 'yes', then the risk is simply the proportion of yes patients in the leaf\n",
    "    - If it is 'no', then the risk is 1 minus the proportion of no patients in the leaf\n",
    "- Decision-Tree Classification model is easy for non-data scientists to understand and apply, to score new patients for their risk of readmission\n",
    "    - Clinicians can readily see what conditions are causing a patient to be scored as high-risk and multiple models can be built and applied at various points during the hospital stay\n",
    "    - This gives a moving picture of the patient's risk and how it is evolving with the various treatments being applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983746b",
   "metadata": {},
   "source": [
    "## Lab: From Problem to Approach\n",
    "In Skills Network linked Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aefb6c7",
   "metadata": {},
   "source": [
    "## Video 4 - Data Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8af4f",
   "metadata": {},
   "source": [
    "##### _Cooking with data_\n",
    "If you try to cook a meal with the wrong ingredients you will fail! So think of data science methodology in this section as cooking with data- each step is critical in making the meal. If the problem that needs to be resolved is the recipe, and data is an ingredient, then data scientists need to define the following:\n",
    "1. Which ingredients are required\n",
    "2. How to source them or collect them\n",
    "3. How to understand or work with them\n",
    "4. How to prepare the data to meet the desired outcome\n",
    "Building on the understanding of the problem at hand, then using the analytical approach selected, the data scientist is ready to get started\n",
    "\n",
    "__From requirements to collection__\n",
    "Examples of Data Requirements in Data Science methodology\n",
    "- prior to undertaking the data collection and data prepartion stages of the methodology, it's vital to define the data requirements for decision-tree classification. This includes:\n",
    "    - Identifying the necessary data content, formats and sources for initial data collection\n",
    "\n",
    "__Case Study: Defining the Data Requirements__\n",
    "First task in the case study was to define the data requirements for the decision tree classification model that was selected\n",
    "- Included selecting a suitable patient cohort from the health insurance providers member base\n",
    "In order to compile the complete clinical histories, three criteria were identified for inclusion in the cohort:\n",
    "1. Patient needed to be admitted as in-patient within the provider service area, need access to the necessary information\n",
    "2. Focused on patients with a primary diagnosis of congestive heart failure during one full year.\n",
    "3. Have continious enrollment for at least six months, prior to the primary admission for congestive heart failure, so that complete medical history could be compiled\n",
    "- Congestive Heart failure patients who also had been diagnosed as having other significant medicial conditions, were excluded from the cohort because those conditions would cause higher-than-average re-admission rates and skew the results\n",
    "Then the content, format, and representations of the data needed for decision tree classification were defined.\n",
    "This modeling technique requires one record per patient, with columns representing the variables in the model.\n",
    "To model the readmission outcome, there needed to be data covering all aspects of the patient's clinical history. This content included:\n",
    "- Admissions\n",
    "- Primary, Secondary, and Teritary diagnoses\n",
    "- Procedures\n",
    "- Prescriptions\n",
    "- Other Services Provided either during hospitalization or throughout the patient/doctor visit\n",
    "Thus a particular patient could have thousands of records, representing all their related attributes.\n",
    "To get to the one record per patient format, the data scientists rolled up the transactional records to the patient level, creating a number of new variables to represent that information.\n",
    "\n",
    "This was a job for the data prepartion stage, so thinking ahead and anticipating subsequent stages is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058e103",
   "metadata": {},
   "source": [
    "## Video 5 - Data Collection\n",
    "\n",
    "After the initial data collection is performed, an assessment by the data scientist takes place to determine whether or not they have what they need.\n",
    "In this phase the data requirements are revised and decisions are made as to whether or not the collection requires more or less data.\n",
    "Techniques such as descriptive statisitcs and visualization can be applied to the dataset to assess the content, quality, and initial insights about the data. Gaps in data will be identified and plans to either fill or make substitutions will have to be made.\n",
    "\n",
    "__Case Study: Gathering Available Data__\n",
    "Collecting data requires that you know the source or, know where to find the data elements that are needed. For this case study this included:\n",
    "1. Demographic\n",
    "2. Clinical and coverage information of patients\n",
    "3. Provider information\n",
    "4. Claims records\n",
    "5. Pharmaceutical and other information related to all the diagnoses of the congestive heart failure patients\n",
    "For this case study, certain information was also needed, but that data source was not yet integrated with the rest of the data sources. This leads to an important point: It is alright to defer decisions about unavailable data, and attempt to acquire it at a later stage.\n",
    "- ex. This can be done after getting some intermediate results from the predictive modeling\n",
    "    - If those results suggest that the drug information might be important in obtaining a good model, then the time needed to get it would be invested\n",
    "    - They were able to build a reasonably good model without this drug information\n",
    "DBAs and programmers often work together to extract data from various sources, and then merge it.\n",
    "- allows for removing redundant data, making it available for the next stage of the methodology, which is data understanding\n",
    "At this stage, if necessary, data scientists and analytics team members can discuss various ways to better manage their data, including automating certain processes in the database, so that data collection is easier and faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810d95d",
   "metadata": {},
   "source": [
    "## Ungraded External Tool: From Requirements to Collection\n",
    "Finished\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553839ee",
   "metadata": {},
   "source": [
    "# Module 2\n",
    "## Video 1 - Data Understanding\n",
    "Data understanding encompasses all activities related to constructing the data set.\n",
    "- Answers the question: Is the data that you collected representative of the problem to be solved?\n",
    "\n",
    "__Case Study: Understanding the Data__\n",
    "In order to understand the data related to congestive heart failure admissions, descriptive statistics needed to be run against the data columns that would become variables in the model:\n",
    "- First, these statisitics included Hearst, univariates, and statisitics on each variable (ex. Mean, Median, Min, Max, Stan Dev.)\n",
    "- Second, pairwise correlations were used, to see how closely certain variables were related, and which ones, if any, were very highly correlated- meaning they would essentially be redundant this making only one relevant for modeling.\n",
    "- Third, histograms of the variables were examined to understand their distributions. \n",
    "    - Histograms are useful to understand how values/variables are distributed and which sorts of data preparation may be needed to make the mvariable more useful in a model.\n",
    "    - ex. a categorical variable that has too many distinct values to be informative in a model, the histogram would help decide how to consolidate those values\n",
    "    \n",
    "Looking at Data Quality - univariates, statisitics, and histograms are also used to assess data quality.\n",
    "- from the information provided, certain values can be re-coded or perhaps even dropped if necessary, such as when a certain variable has missing values.\n",
    "\n",
    "The question then becomes: _does \"missing\" mean anything?_\n",
    "- Sometimes a missing value will be assigned a 'No' or '0'\n",
    "- Other times it simply means \"we do not know\"\n",
    "- Variables can contain invalid or misleading values that can be still treated as valid value unless corrected\n",
    "\n",
    "Initially, the meaning of congestive heart fialure admission was decided on the basis of a primary diagnosis of Congestive Heart Failure\n",
    "- Working through the data understanding stage revealed that the initial definition was not capturing CHF admissions that were expected, based on clinical experience\n",
    "- This meant looping back to the data collection stage and adding secondary and tertiary diagnoses, and building a more comprehensive definition of CHF admissions.\n",
    "\n",
    "__Takeway__: The more one works with the problem and the data, the more one learns and therefore the more refinement that can be done within the model, ultimately leading to a better solution to the problem\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd9374",
   "metadata": {},
   "source": [
    "## Video 2 - Data Preparation - Concepts\n",
    "Data Preparation is the most time consuming phase of a data science project (Typically taking 70%-90% of overall project time)\n",
    "Automating some of the data collection and preparation processes in the database can reduce this time to as little as 50%\n",
    "- This time savings translate into increased time for data scientists to focus on creating models\n",
    "\n",
    "Transforming data in the data preparation phase is the process of getting the data into a state where it may be easier to work with.\n",
    "Specifically, data prep answers the question: _What are the ways in which data is prepared?_\n",
    "To work effectively with the data, it must be prepared in a way that addresses missing or invalid values and removes duplicates\n",
    "- This is towards ensuring that everything is properly formatted\n",
    "\n",
    "Feature Engineering - Process of Using Domain Knowledge of the data to create features that make the machine learning algorithms.\n",
    "- Feature engineering is critical when machine learning tools are being applied to analyze the data.\n",
    "Feature - Characterisitic that might help when solving a problem\n",
    "- Features within the data are important to predictive models and will influence the results you want to achieve\n",
    "\n",
    "__Feature Engineering__ is critical when machine learning tools are being applied to analyze the data.\n",
    "\n",
    "When working with text, text analysis steps for coding the data are required to be able to manipulate the data.\n",
    "- Data scientist needs to know what they're looking for within their datasets to address the question\n",
    "- Text analysis is critical to ensure that the proper groupings are set, and the programming is not overlooking what is hidden within\n",
    "\n",
    "Data prep phase sets the stage for the next steps in addressing the question.\n",
    "- While this phase is time intensive, if done right the results will support the project.\n",
    "- If this skipped, the outcome may be unsubstantive and may have you back at the drawing board.\n",
    "\n",
    "_\"It takes one bad ingredient to ruin a fine meal\"_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981a870",
   "metadata": {},
   "source": [
    "#### Note by IBM Skills Network - Correction - in the next video on the case study the phrase ___\"Literary Review\"___, this is supposed to be \"___Literature___ Review\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a1086",
   "metadata": {},
   "source": [
    "## Video 3 - Data Preparation - Case Study\n",
    "An important first step in the data prep stage was to define CHF\n",
    "- Sounded easy at first but defining it precisely was not straightforward\n",
    "\n",
    "1. Set of diagnosis-related group codes needed to be identified, CHF implies certain kinds of fluid buildup\n",
    "2. Need to consider CHF is only one type of heart failure -- Clinical Guidance was needed to get the right codes for CHF\n",
    "3. Define the re-admission criteria for the same condition\n",
    "- Timing of events needed to be evaluated in order to define whether a particular CHF admission was an initial event (Index Admission), or a CHF-related re-admission\n",
    "- Based on clinical expertise, a time period of 30 days was set as the window for readmission revelant to CHF patient, following the discharge from the initial admission\n",
    "4. Records in transactional format were aggregated -- meaning that the data included multiple records for each patient\n",
    "- Transactional records included:\n",
    "    1. Professional Provider Facility Claims submitted for Physician, laboratory, hospital, and clinical services\n",
    "    2. Records describing all the diagnoses, procedures, prescripitions, and other information about in-patients and out-patients\n",
    "        - a given patient could easily have hundreds to thousands of these records depending on their clinical history\n",
    "5. The transactional records were aggregated to the patient level, yielding a single record for each patient, as required for the decision-tree classification method that would be used for modeling.\n",
    "\n",
    "As part of the aggregation process, many new columns were created representing the information in the transactions:\n",
    "- Frequency and most recent visits to doctors\n",
    "- Clinics and hospitals with diagnoses\n",
    "- Procedures\n",
    "- Prescriptions, etc.\n",
    "\n",
    "Co-morbidities with CHF were also considered (such as diabetes, hypertension, and more that had impact on potential risk of re-admission)\n",
    "\n",
    "During discussions around data prep, a __literature review__ on CHF was also undertaken to determine if their were factors overlooked (ex. Co-Morbidities not yet accounted for)\n",
    "- The literature review involved looping back to the data collection stage to add a few more indicators for conditions and procedures\n",
    "\n",
    "Aggregating the transactional data at the patient level, meant merging it with the other patient data, including their demographic information, such as age, gender, type of insurance, etc.\n",
    "- Result: One table containing a single record per patient with many columns representing the attributes about the patient in his or her clinical history. These columns would be used as variables in the predictive modeling.\n",
    "\n",
    "List of Variables used in Building the model in video\n",
    "Dep Var: CHF Readmission within 30 days of discharge from a hospitalization for CHF -- with an outcome of either yes or no.\n",
    "\n",
    "Data Preparation stage resulted in a cohort of 2,343 patients meeting all of the criteria for the case study\n",
    "- Cohort was then split into training and testing sets for building and validating the model\n",
    "|Set | Percentage | Number of Patients |\n",
    "|----|------------|--------------------|\n",
    "| Training | (70%) | 1,640 patients |\n",
    "| Testing | (30%) | 703 patients |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa87e7d",
   "metadata": {},
   "source": [
    "## Ungraded External Tool: From Understanding to Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8ca9e",
   "metadata": {},
   "source": [
    "# Module 2 Pt. 2 - From Modeling to Evaluation\n",
    "## Video 1 - Modeling - Concepts\n",
    "This portion of the course is geared towards answering two key questions:\n",
    "1. What is the Purpose of Data Modeling\n",
    "2. What are some characterisitics of this process?\n",
    "\n",
    "Data modeling focuses on developing models that are either descriptive or predictive.\n",
    "- Descriptive Model ex.\n",
    "    - If a person did _this_, then they are likely to prefer _that_\n",
    "- Predictive Model tries to yield yes/no or stop/go type outcomes\n",
    "    - These models are based on the analytic approach that was taken, either statisitically driven or machine learning driven.\n",
    "    - Data Scientist will use a training set for predictive modeling\n",
    "    - Training set acts like a guage to determine if the model needs to be calibrated\n",
    "    - During this stage, data scientist will play around with different algorithms to ensure that the variables in play are required\n",
    "    \n",
    "__The success of data compilation, preparation, and modelling depends on the understanding of the problem at hand, and the appropriate analytical approach being taken__\n",
    "- Data supports the answering of the question, and like the quality of the ingredients in cooking, sets the stage for the outcome\n",
    "- Constant refinement, adjustments, and tweaking are necessary within each step to ensure the outcome is one that is solid\n",
    "\n",
    "John Rollin's descriptive Data Science Methodology framework is geared to do 3 things:\n",
    "1. Understand the question\n",
    "2. Select an analytical approach to answer the question\n",
    "3. Obtain, understand, prepare, and model the data\n",
    "End goal is to move the data scientist to a point where a data model can be built to answer the question\n",
    "\n",
    "In this stage of the methodology, model evaluation, deployment, and feedback loops ensure that the answer is near and relevant.\n",
    "Data Science is new and evolving, we want to see the possibilities it has to offer -- the more people that benefit from the outcomes of this practice, the further the field will develop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a56ba",
   "metadata": {},
   "source": [
    "## Video 2 - Modeling - Case Study\n",
    "__Analyzing the 1st Model__\n",
    "Table on First Slide\n",
    "|Model|Relative Cost Y:N|Overall Accuracy (% correct Y & N)|Sensitivity(Y accuracy)|Specificity(N accuracy)|\n",
    "|-----|-----------------|----------------------------------|-----------------------|-----------------------|\n",
    "| 1 | 1:1 | 85% | 45% | 97% |\n",
    "| 2 | 9:1 | 49% | 97% | 35% |\n",
    "| 3 | 4:1 | 81% | 68% | 85% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824c608",
   "metadata": {},
   "source": [
    "With a prepared training set, the first decision tree model for CHF failure readmission can be built.\n",
    "- We are looking for patients with high-risk readmission, so the outcome of interest will be CHF readmission = \"yes\"\n",
    "\n",
    "In the first model overall accuracy was 85%. This sounds good, but this only represents 45% of the yes. The actual readmissions are correctly classified, meaning that the model is not very accurate.\n",
    "\n",
    "The question then becomes: _How could the accuracy of the model be improved in predicting the yes outcome?_\n",
    "- for decision tree classification, the best parameter to adjust is the relative cost of misclassified y/n outcomes\n",
    "\n",
    "When a true, non-readmission is misclassified, and action is taken to reduce that patient's risk, the cost of the error is the wasted intervention. A statisitician calls this a __type I error__, or a _false-positive_.\n",
    "But when a true readmission is misclassified, and no action is taken to reduce that risk, then the cost of that error is the readmission and all its attended costs, plus the trauma of the patient.  A statisitician calls this a __type II error__, or a _false-negative_.\n",
    "- We can see that the cost of the misclassification errors can be quite different\n",
    "- For this reason it is reasonable to weigh their value differently\n",
    "- The next two models shift the value for yes\n",
    "\n",
    "The second model used a 9:1 weight for relative cost.\n",
    "- Correctly classified 97% of the yes, but at the expense of a very low accuracy on the no.\n",
    "- Overall Accuracy of only 49%.\n",
    " _So this is not a good model_. It would cause too many false positives which would cause unnecessary and costly intervention for patients, who would not have been readmitted anyway.\n",
    " \n",
    "_Therefore_, the data scientist needs to try again to find a better balance between the yes and no accuracies.\n",
    "\n",
    "For the third model, the relative cost was set at 4:1. _Bit more reasonable_.\n",
    "- 68% accuracy on yes\n",
    "- 85% accuracy on no\n",
    "- 81% accuracy overall\n",
    "This is the best balance that can be obtained with a rather small training set through adjusting y:n relative cost misclassification parameter.\n",
    "\n",
    "_A lot_ more work goes into the modeling\n",
    "- Including iterating back to the data prep stage to redefine some of the variables, so as to better represent the underlying info, and therefore improve the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44ca7b",
   "metadata": {},
   "source": [
    "## Video 3 - Evaluation\n",
    "A model evaluation goes hand-in-hand with model building as such, the modeling and evaluation stages are done iteratively.\n",
    "- Performed during model development and before the model is deployed\n",
    "- Allows th quality of the model to be assessed but it's also an opportunity to see if it meets the initial request.\n",
    "\n",
    "Evaluation answers the question: Does the model used really answer the initial question or does it need to be adjusted?\n",
    "\n",
    "Model Evaluation has two main phases:\n",
    "1. Diagnostic Measures Stage\n",
    "- Ensure the model is working as intended\n",
    "- ex. if the model is a predictive model, a decision tree can be used to evaluate if the answer the model can output, is aligned to the initial design. It can be used to see where there are areas that require adjustments.\n",
    "- ex. if the model is a descripitive model, one in which relationships are being assessed, then a testing set can be applied, and the model can be refined as needed\n",
    "2. Statisitical Significance Testing\n",
    "- Ensures the data is being properly handled and interpreted within the model\n",
    "- This is designed to avoid unnecessaru second guessing when the answer is revealed\n",
    "\n",
    "__Case Study__\n",
    "\n",
    "Table 1\n",
    "|Model|Relative Cost Y:N|True Positive Rate(Sensitivity)|Specificity(accuracy on N)|False Positive Rate(1-Specificity)|\n",
    "|-----|-----------------|-------------------------------|--------------------------|----------------------------------|\n",
    "| 1 | 1:1 | 0.45 | 0.97 | 0.03 |\n",
    "| 2 | 1.5: 1 | 0.60 | 0.92 | 0.08 |\n",
    "| 3 | 4:1 | 0.68 | 0.85 | 0.15 |\n",
    "| 4 | 9:1 | 0.97 | 0.35 | 0.65 |\n",
    "\n",
    "Again, we will be tuning the relative cost of misclassifying yes and no answers.\n",
    "Four models were built. Notice that the models continuously improve on the sensitivity (Y) but at the expense of lower accuracy on specificity (No), creating an increasing false positive rate.\n",
    "So which is best?\n",
    "- For budgetary reasons, the risk-reducing intervention could not be applied to most or all CHF patients, many of whom would not have been readmitted anyway.\n",
    "- On the other hand, the intervention would not be as effective in improving patient care as it should be, with not enough high-risk congestive heart failure patients targeted\n",
    "\n",
    "__Finding the Optimial Model using an ROC curve__\n",
    "Figure is in video.\n",
    "The optimal model is the one giving the maximum separation between the blue ROC curve and the red base line.\n",
    "Model 3, with a relative cost of 4:1, is the best of the 4 models\n",
    "__ROC Curve__ - Receiver Operating Characteristic Curve\n",
    "- Originated to detect enemy aircraft on radar, but since has been adapted to many industries\n",
    "- Today is commonly used in Machine Learning and Data Mining\n",
    "ROC Curve is a useful diagnostic tool in determining the optimal classification model.\n",
    "This curve quantifies how well a binary classification model performs, declassifying the yes and no outcomes when some discrimination criterion is varied. In this case, the criterion is a relative misclassification cost.\n",
    "By plotting the true-positive rate against the false-positive rate for different values of the relative misclassification cost, the ROC curve helped in selecting the optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b40bf",
   "metadata": {},
   "source": [
    "# Module 3 - From Deployment to Feedback\n",
    "## Video 1 - Deployment\n",
    "While a data science model will provide an answer, the key to making the answer relevant and useful to address the initial question, involves getting the stakeholders familiar with the tool produced.\n",
    "- In a business scenario, stakeholders have different specialities that will help make this happen. Such as:\n",
    "    - Solution Owner\n",
    "    - Marketing\n",
    "    - Application Developers\n",
    "    - IT Administration\n",
    "Once the model is evaluated and the data scientist is confident it will work, it is deployed and put to the ultimate test.\n",
    "Depending on the purpose of the model, it may be rolled out to a limited group of users or in a test environment, to build up confidence in applying the outcome for use across the board.\n",
    "\n",
    "__Case Study___\n",
    "In preparation for solution deployment, the next step was to assimilate the knowledge for the business group who would be designing and managing the intervention program to reduce readmission risk.\n",
    "- In this scenario, the business people translated the model results so that the clinical staff could understand how to identify high-risk patients and design suitable intervention actions\n",
    "- Goal: Decrease likelihood these patients would be readmitted 30 days after discharge\n",
    "\n",
    "During the business requirements stage, the Intervention Program Director and her team had wanted an application that would provide automated, near real-time risk assessments of CHF. Also, it had to be easy for staff to use and preferably would be a browser-based application that each staff member could carry around. \n",
    "- This patient data was generated throughout the hospital stay\n",
    "- Automatically prepared in a format needed by the model and each patient would be scored near the time of discharge\n",
    "    - Allows clinicians to have most up-to-date risk assessment for each patient, helping them to select for intervention after discharge.\n",
    "- As part of the solution deployment, the Intervention team would develop and deliver training for the clinical staff.\n",
    "- Processes for tracking and monitoring patients receiving the intervention would have to be developed in collaboration with IT Devs and DBAs, so that the results could go through the feedback stage and the model could be refined over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36af8a",
   "metadata": {},
   "source": [
    "## Video 2 - Feedback\n",
    "Once deployed, feedback from the users will help to refine the model and assess it for performance and impact. The value of the model will be dependent on successfully incorporating feedback and making adjustments for as long as the solution is required. \n",
    "\n",
    "Throughout the data science methodology, each step sets the stage for the next. Making the methodology cycical, ensures refinement at each stage in the game. The feedback process is rooted in the notion that the 'more-you-know', the more tha you'll want to know \n",
    "\n",
    "__Case Study__\n",
    "Plan for feedback stage steps:\n",
    "1. Review Process would be defined and put into place, with overall responsibility for measuring the results of a \"flying to risk\" model of the CHF risk population.\n",
    "    - Clinical Management executives would have overall responsibility for the review process.\n",
    "2. CHF Patients receiving intervention would be tracked and their re-admission outcomes reported\n",
    "3. The intervention would then be measured to determine how effective it was in reducing readmission risk\n",
    "    - ___For ethicial reasons___, CHF patients would not be split into a controlled and treatment group\n",
    "    - Instead, readmission rates would be compared before and after the implementation of the model to measure its impact.\n",
    "\n",
    "After the deployment and feedback stages, the impact of the intervention program on re-admission rates would be reviewed after the first year of its implementation. Then the model would be refined, based on all of the data compiled after model implementation and the knowledge gained throughout these stages.\n",
    "Other refinements included:\n",
    "- Incorporating information about participation in the intervention program\n",
    "- Possibly refining the model to incorporate detailed pharmaceutical data\n",
    "    - Recall that data collection was initially deferred because the pharma data was not readily available at the time.\n",
    "    - Could be determined that adding the data could be worth the investment of effort and time\n",
    "    \n",
    "We also have to allow for the possibility that other refinements might present themselves during the feedback stage. Also, the intervention actions and processes would be reviewed and very likely refined as well, based on the experience and knowledge gained through the initial deployment and feedback.\n",
    "\n",
    "Finally, the refined model and intervention actions would be redeployed, with the feedback process continued throughout the life of the intervention program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88159125",
   "metadata": {},
   "source": [
    "## Video 3 - Course Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e3acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
